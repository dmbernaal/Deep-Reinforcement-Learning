{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning Algorithm\n",
    "Our **MiniMax Algorithm** is superior when the given game is:\n",
    "* Small\n",
    "* Deterministic\n",
    "* Has Perfect Information \n",
    "\n",
    "For example: A Game of Tic-Tac-Toe would be the perfect 'enviroment' whereas there are ~300,000 possible game scenarios. \n",
    "\n",
    "This may become troublesome when building algorithms for much more complex games such as: Chess, Checkers, Go. In fact in Chess & Go, there are more possible board positions than there are atoms in the obersvable universe. \n",
    "\n",
    "This is where **Pruning** comes into play.\n",
    "\n",
    "## Trees\n",
    "We need to think of these algorithms as trees where the **Width** of the tree represents the number of possible moves and the **Depth** represents the number of turns. \n",
    "\n",
    "So a thought experiment to have before building any algorithm for a game is to: *Estimate the **size** of the tree.* \n",
    "\n",
    "A good way to estimate this is: \n",
    "$$W^d$$\n",
    "\n",
    "* $W$ = Average width\n",
    "* $d$ = Average depth\n",
    "\n",
    "Example: \n",
    "\n",
    "**Go** typically has **250** legal moves **per turn**, and a game might last **150 turns**. \n",
    "Thus: \n",
    "\n",
    "$$W^d ≈ 250^{150} ≈ 10^{359}$$\n",
    "\n",
    "That is, $10^{359}$ positions. That's 359 zeros... \n",
    "\n",
    "## Pruning\n",
    "The intuition behind **Pruning** is that when reducing the width or depth of our (tree) search, we drastically reduce the time needed to select a move."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position Evaluation Functions\n",
    "Are used for reducing the **Search Depth**. The intuition behind this is the sense of who's in the lead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_result(game_state, max_depth, eval_fn):\n",
    "    \"\"\"\n",
    "    This function will return a number indicating the value of your board evaluation function. A large score means the player who has the next move expects to win. When you evaluate the board from your opponents perspective, you multiply the score by -1 to flip back to your perspective. \n",
    "    \n",
    "    ARGs:\n",
    "        game_state: the given game state of that legal move (usualy future game state)\n",
    "        max_depth: controls the number of moves you want to search ahead. We subtract 1 each turn, then call our board evaluation function\n",
    "        eval_fn: A functions who's job is to evaluate the board \n",
    "    \"\"\"\n",
    "    # Checking if game is over, this is a recursive function so we call this first\n",
    "    if game_state.is_over():\n",
    "        if game_state.winner() == game_state.next_player:\n",
    "            return MAX_SCORE # 3\n",
    "        else:\n",
    "            return MIN_SCORE # 1\n",
    "    \n",
    "    # Have we reached the maximum depth search? - we subtract one every time this function is called \n",
    "    if max_depth == 0:\n",
    "        return eval_fn(game_state) # this is essentually the 'loss function'\n",
    "    \n",
    "    # Initialize with lowest score\n",
    "    best_so_far = MIN_SCORE\n",
    "    \n",
    "    # Loop through all possible, legal moves\n",
    "    for candidate_move in game_state.legal_moves():\n",
    "        \n",
    "        # Calculating what the board would look like playing this legal move\n",
    "        next_state = game_state.apply_move(candidate_move)\n",
    "        \n",
    "        # What is the opponents best position if we play that legal move?\n",
    "        opponent_best_result = best_result(next_state, max_depth - 1, eval_fn)\n",
    "        \n",
    "        # Inver their best results\n",
    "        our_result = -1 * opponent_best_result\n",
    "        \n",
    "        # is this better than our best result so far?\n",
    "        if our_result > best_result:\n",
    "            best_so_far = our_result\n",
    "            \n",
    "    return best_so_far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE EVAL FUNCTION - highly simplified board evaluation heuristic for Go. Check out: www.github.com/dmbernaal/SigmaGo.git for details on other variables & functions here \n",
    "def capture_diff(game_state):\n",
    "    \"\"\"\n",
    "    This is a simple board evaluation heuristic for go. Such evaluation function would go as the second argument in best_result()\n",
    "    \n",
    "    This function calculates the difference in # of stones captured. The player with more stones captured is the 'leader' \n",
    "    \"\"\"\n",
    "    black_stones = 0 \n",
    "    white_stones = 0\n",
    "    for r in range(1, game_state.board.num_rows + 1):\n",
    "        for c in range(1, game_state.board.num_cols + 1):\n",
    "            p = gotypes.Point(r, c)\n",
    "            color = game_state.board.get(p)\n",
    "            if color == gotypes.Player.black:\n",
    "                black_stones += 1\n",
    "            elif color == gotypes.Player.white:\n",
    "                white_stones += 1\n",
    "    diff = black_stones - white_stones\n",
    "    if game_state.next_player == gotypes.Player.black:\n",
    "        return diff\n",
    "    return -1 * diff # if player is white"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha-Beta Pruning\n",
    "Are used for reducing the **Search Width** The time savings you get by alpha-beta pruning depends on how quickly you find good branches. If you happen to evaluate the best branches early on, you can eliminate the other branches quickly. \n",
    "\n",
    "To implement this algorithm, you must track the best result so far for each player throughout your search:\n",
    "* **Alpha** = ```best_black```\n",
    "* **Beta** = ```best_white```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_beta_result(game_state, max_depth, best_black, best_white, eval_fn):\n",
    "    \"\"\"\n",
    "    ARGs:\n",
    "        game_state: The given game state provided the move\n",
    "        max_depth: How deep in the tree will we evaluate? - similar to other function\n",
    "        best_black: alpha or beta?\n",
    "        best_white: alpha or beta?  (opposite of best_black)\n",
    "        eval_fn: our 'loss function', we use capture_diff() in this example\n",
    "    \"\"\"\n",
    "    # Checking if game is already over\n",
    "    if game_state.is_over():\n",
    "        if game_state.winner() == game_state.next_player:\n",
    "            return MAX_SCORE \n",
    "        else:\n",
    "            return MIN_SCORE\n",
    "     \n",
    "    # have you reached your maximum depth?\n",
    "    if max_depth == 0:\n",
    "        return eval_fn(game_state)\n",
    "    \n",
    "    # Initializing best so far = 1\n",
    "    best_so_far = MIN_SCORE\n",
    "    \n",
    "    # Looping over all legal moves\n",
    "    for candidate_move in game_state.legal_moves():\n",
    "        \n",
    "        # What will the board look like if you play this legal move?\n",
    "        next_state = game_state.apply_move(candidate_move)\n",
    "        \n",
    "        # What is your opponents best result from that position? (move)\n",
    "        opponent_best_result = alpha_beta_result(next_state, max_depth - 1, best_black, best_white, eval_fn)\n",
    "        \n",
    "        # Whatever our opponent wants, we want the opposite\n",
    "        our_result = -1 * opponent_best_result\n",
    "        \n",
    "        # Is our result the best we've seen so far? \n",
    "        if our_result > best_so_far:\n",
    "            best_so_far = our_result\n",
    "        \n",
    "        # updating benchmark for white\n",
    "        if game_state.next_player == Player.white:\n",
    "            if best_so_far > best_white:\n",
    "                best_white = best_so_far\n",
    "            outcome_for_black = -1 * best_so_far\n",
    "            \n",
    "            # picking the best move for white\n",
    "            if outcome_for_black < best_black:\n",
    "                return best_so_far\n",
    "        \n",
    "        # updating benchmark for black\n",
    "        elif game_state.next_player == Player.black:\n",
    "            if best_so_far > best_black:\n",
    "                best_black = best_so_far\n",
    "            outcome_for_white = -1 * best_so_far\n",
    "            \n",
    "            # picking best move for black\n",
    "            if outcome_for_white < best_white:\n",
    "                return best_so_far\n",
    "    \n",
    "    return best_so_far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
