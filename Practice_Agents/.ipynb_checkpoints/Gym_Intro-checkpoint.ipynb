{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "This point of this notebook is to familarize with the workflow behind creating an environment, playing around with observations of the enviromment, and creating an agent to act on the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our environment with Gym\n",
    "environment = 'CartPole-v0'\n",
    "env = gym.make(environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we always need to reset the newly created environment\n",
    "obs = env.reset() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions Spaces for environment: \n",
      "Discrete(2)\n",
      "\n",
      "Observation Spaces for environment: \n",
      "Box(4,)\n",
      "\n",
      "Observaion: \n",
      "[ 0.00416141 -0.04089205  0.01074641  0.01193437]\n"
     ]
    }
   ],
   "source": [
    "# Grabbing information about the new environment\n",
    "action_space = env.action_space\n",
    "observation_space = env.observation_space\n",
    "\n",
    "print(f'Actions Spaces for environment: \\n{action_space}\\n')\n",
    "print(f'Observation Spaces for environment: \\n{observation_space}\\n')\n",
    "print(f'Observaion: \\n{obs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```action_space``` is of ```Discrete``` type, so our actions will be just 0 or 1:\n",
    "* 0: pushing the platform to left\n",
    "* 1: pushing the platform to right\n",
    "\n",
    "```observation_space``` is of ```Box(4,)```, which means: A vector of size four with values inside: ```[-inf, inf]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.00334357, -0.23616646,  0.0109851 ,  0.30798845]), 1.0, False, {})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's push platform to left:\n",
    "env.step(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returned a tuple of values:\n",
    "* A new observation that is a new vector of four numbers\n",
    "* A reward of 1.0\n",
    "* ```done``` flag is ```False```, which means the episode is not over yet\n",
    "* Extra information about the enviroment that is an empty dictionary here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New observation: \n",
      "[-0.00137976 -0.4314432   0.01714487  0.60411544]\n",
      "\n",
      "Our reward: \n",
      "1.0\n",
      "\n",
      "Is the episode over?: \n",
      "False\n",
      "\n",
      "Is there any information?: \n",
      "{}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In detail:\n",
    "first_step = env.step(0)\n",
    "\n",
    "print(f'New observation: \\n{first_step[0]}\\n')\n",
    "print(f'Our reward: \\n{first_step[1]}\\n')\n",
    "print(f'Is the episode over?: \\n{first_step[2]}\\n')\n",
    "print(f'Is there any information?: \\n{first_step[3]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's pick a random discrete action [0,1]\n",
    "e.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's pick another random discrete action [0,1]\n",
    "e.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.0658181e+00,  6.9937125e+37,  3.7601247e-02, -5.1957849e+37],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
